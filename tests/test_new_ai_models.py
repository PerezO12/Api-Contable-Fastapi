#!/usr/bin/env python3
"""
Script para probar los nuevos modelos de IA implementados
"""
import asyncio
import logging
import os
import sys

# Agregar el directorio de la aplicaciÃ³n al path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.hf_client import hf_client
from app.services.translation import translation_service
from app.config import settings

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_models():
    """Prueba los modelos de IA implementados"""
    
    print("ğŸ§ª Probando nuevos modelos de IA")
    print("=" * 50)
    
    # Verificar configuraciÃ³n
    print(f"Token configurado: {settings.HUGGINGFACE_API_TOKEN[:10]}...")
    print(f"Modelo principal: {hf_client.model_name}")
    print(f"Modelos fallback: {hf_client.fallback_models}")
    print()
    
    # 1. Probar disponibilidad de modelos
    print("1. Verificando disponibilidad de modelos...")
    models_to_check = [hf_client.model_name] + hf_client.fallback_models[:3]  # Solo los primeros 3
    
    for model in models_to_check:
        health = await hf_client.check_model_health(model)
        status_icon = "âœ…" if health["available"] else "âŒ"
        error_msg = health.get("error", "Sin error especÃ­fico")
        status_msg = "Disponible" if health["available"] else f"No disponible - {error_msg}"
        print(f"   {status_icon} {model}: {status_msg}")
    
    print()
    
    # 2. Encontrar modelo disponible
    print("2. Buscando modelo disponible...")
    available_model = await hf_client.find_available_model()
    if available_model:
        print(f"   âœ… Modelo recomendado: {available_model}")
    else:
        print("   âŒ No se encontrÃ³ ningÃºn modelo disponible")
        return
    
    print()
    
    # 3. Probar generaciÃ³n bÃ¡sica
    print("3. Probando generaciÃ³n bÃ¡sica...")
    test_prompt = "Hello, how can I help you today?"
    
    try:
        response = await hf_client.generate_with_retry(test_prompt)
        if response and response.strip():
            print(f"   âœ… Respuesta recibida: {response[:100]}...")
        else:
            print("   âŒ No se recibiÃ³ respuesta vÃ¡lida")
    except Exception as e:
        print(f"   âŒ Error en generaciÃ³n: {e}")
    
    print()
    
    # 4. Probar generaciÃ³n multilingÃ¼e (si estamos usando BloomZ)
    if "bloomz" in available_model.lower():
        print("4. Probando capacidades multilingÃ¼es de BloomZ...")
        
        multilingual_prompts = [
            "Hola, Â¿cÃ³mo estÃ¡s?",
            "OlÃ¡, como vocÃª estÃ¡?", 
            "Bonjour, comment allez-vous?"
        ]
        
        for prompt in multilingual_prompts:
            try:
                response = await hf_client.generate_response(prompt)
                print(f"   ğŸ“ '{prompt}' -> '{response[:80] if response else 'Sin respuesta'}...'")
            except Exception as e:
                print(f"   âŒ Error con '{prompt}': {e}")
    
    print()
    
    # 5. Probar generaciÃ³n con formato de factura
    print("5. Probando generaciÃ³n con instrucciones de factura...")
    invoice_prompt = "Create an invoice for John Doe with 1 laptop for $500"
    
    try:
        invoice_response = await hf_client.generate_response_with_invoice_support(invoice_prompt)
        if invoice_response:
            print(f"   âœ… Respuesta de factura: {invoice_response[:150]}...")
            
            # Verificar si contiene JSON
            if "create_invoice" in invoice_response and "{" in invoice_response:
                print("   ğŸ¯ Â¡Formato JSON detectado!")
            else:
                print("   â„¹ï¸  Respuesta conversacional (no JSON)")
        else:
            print("   âŒ No se recibiÃ³ respuesta para factura")
    except Exception as e:
        print(f"   âŒ Error en generaciÃ³n de factura: {e}")
    
    print()
    
    # 6. Probar integraciÃ³n con traducciÃ³n
    print("6. Probando integraciÃ³n con traducciÃ³n...")
    try:
        # Verificar que el servicio de traducciÃ³n estÃ© disponible
        if hasattr(translation_service, 'process_text'):
            test_spanish = "Crea una factura para MarÃ­a GonzÃ¡lez"
            detected_lang, original, english = translation_service.process_text(test_spanish)
            print(f"   ğŸ“‹ Original: {original}")
            print(f"   ğŸŒ Idioma detectado: {detected_lang}")
            print(f"   ğŸ”„ Traducido: {english}")
            
            # Respuesta de IA en inglÃ©s
            ai_response = await hf_client.generate_response_with_invoice_support(english)
            if ai_response:
                # Traducir de vuelta
                back_translated = translation_service.translate_from_english(ai_response[:100], detected_lang)
                print(f"   ğŸ¤– Respuesta IA: {ai_response[:80]}...")
                print(f"   ğŸ”„ De vuelta a {detected_lang}: {back_translated}")
            
        else:
            print("   âš ï¸  Servicio de traducciÃ³n no disponible")
            
    except Exception as e:
        print(f"   âŒ Error en integraciÃ³n de traducciÃ³n: {e}")
    
    print()
    print("ğŸ‰ Prueba completada!")
    
    # Cerrar cliente HTTP
    await hf_client.close()


async def main():
    """FunciÃ³n principal"""
    try:
        await test_models()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Prueba cancelada por el usuario")
    except Exception as e:
        logger.error(f"Error en prueba principal: {e}")
        print(f"âŒ Error inesperado: {e}")


if __name__ == "__main__":
    asyncio.run(main())
